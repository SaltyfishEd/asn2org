#!/usr/bin/env python3

"""AS number to organization names CSV generator

This script produces a CSV file translating AS numbers to organization
names. It relies on PeeringDB and IRR databases.

This file is released under the CC0-1.0 license (public domain).
"""

import argparse
import csv
import gzip
import json
import logging
import logging.handlers
import os
import sys
from datetime import datetime, timedelta

import requests

logger = logging.getLogger(os.path.splitext(os.path.basename(sys.argv[0]))[0])


class CustomFormatter(
    argparse.RawDescriptionHelpFormatter, argparse.ArgumentDefaultsHelpFormatter
):
    pass


def parse_args(args=sys.argv[1:]):
    """Parse arguments."""
    parser = argparse.ArgumentParser(
        description=sys.modules[__name__].__doc__, formatter_class=CustomFormatter
    )

    parser.add_argument(
        "--debug", "-d", action="store_true", default=False, help="enable debugging"
    )

    g = parser.add_argument_group("inputs")
    g.add_argument(
        "--peeringdb-url",
        default="https://www.peeringdb.com/api",
        type=str,
        help="PeeringDB API URL",
    )
    g.add_argument(
        "--afrinic-url",
        default="http://ftp.afrinic.net/dbase",
        type=str,
        help="AFRINIC (RIR) URL",
    )
    g.add_argument(
        "--apnic-url",
        default="http://ftp.apnic.net/apnic/whois",
        type=str,
        help="APNIC (RIR) URL",
    )
    g.add_argument(
        "--arin-url",
        default="http://ftp.arin.net/pub/rr",
        type=str,
        help="ARIN (RIR) URL",
    )
    g.add_argument(
        "--lacnic-url",
        default="http://ftp.lacnic.net/lacnic/irr",
        type=str,
        help="LACNIC (RIR) URL",
    )
    g.add_argument(
        "--ripe-url",
        default="http://ftp.ripe.net/ripe/dbase/split",
        type=str,
        help="RIPE (RIR) URL",
    )
    v = datetime.strftime(datetime.now() - timedelta(10), "%Y-%m")
    g.add_argument(
        "--db-ip-url",
        default=f"https://download.db-ip.com/free/dbip-asn-lite-{v}.csv.gz",
        type=str,
        help="DB-IP IP to ASN lite database",
    )

    g = parser.add_argument_group("output")
    g.add_argument(
        "--csv-dialect",
        default="unix",
        choices=csv.list_dialects(),
        help="dialect for CSV output",
    )

    return parser.parse_args(args)


def setup_logging(options):
    """Configure logging."""
    root = logging.getLogger("")
    root.setLevel(logging.WARNING)
    logger.setLevel(options.debug and logging.DEBUG or logging.INFO)
    ch = logging.StreamHandler()
    ch.setFormatter(logging.Formatter("%(levelname)s[%(name)s] %(message)s"))
    root.addHandler(ch)


def download(url, target):
    """Download an URL to the specified target except if it already exists."""
    if not os.path.exists(target):
        logger.info(f"download {url}")
        r = requests.get(url, allow_redirects=True)
        r.raise_for_status()
        with open(target, "wb") as f:
            f.write(r.content)
    else:
        logger.info(f"use existing copy for {url}")


def from_csv(source, url, asn=0, name=1):
    """Return ASN to organization mapping from the provided CSV."""
    logger.debug(f"processing CSV file {url}")
    target = url.split("/")[-1]
    download(url, target)

    with gzip.open(target, "rt") as input:
        return {
            int(row[asn]): (row[name], source)
            for row in csv.reader(input, dialect="unix")
            if not row[name].startswith("-")
        }


def from_irr(source, *urls):
    """Return ASN to organization mapping from provided IRR database."""
    autnums = {}
    orgs = {}

    for url in urls:
        logger.debug(f"processing IRR {url}")
        target = url.split("/")[-1]
        download(url, target)

        current = None
        with gzip.open(target, "rt", errors="replace") as input:
            for line in input:
                line = line.strip()
                if not line:
                    current = None
                    continue
                field, _, value = line.partition(":")
                value = value.strip()
                if not value:
                    continue

                if field == "aut-num" and current is None:
                    current = field
                    autnum = int(value[2:])
                elif field == "org" and current == "aut-num":
                    autnums[autnum] = value.lower()
                elif (
                    field == "descr" and current == "aut-num" and autnum not in autnums
                ):
                    # For ARIN/LACNIC
                    autnums[autnum] = value
                elif field == "organisation" and current is None:
                    current = field
                    org = value.lower()
                elif field == "org-name" and current == "organisation":
                    orgs[org] = value

    return {asn: (orgs.get(org, org), source) for asn, org in autnums.items()}


def from_peeringdb(peeringdb_url):
    """Return ASN to organization mapping from PeeringDB."""
    logger.debug("processing PeeringDB")
    download(f"{peeringdb_url}/net", "peeringdb.db.json")
    with open("peeringdb.db.json") as input:
        data = json.load(input)
    return {d["asn"]: (d["name"], "PeeringDB") for d in data["data"]}


def clean(name, asn, source):
    """Clean AS name to remove cruft. This includes removing the
    repetition of the AS number or the "LLC" or ", Inc." present in
    some AS names."""
    cleaned = name
    previous = None
    while cleaned != previous:
        previous = cleaned
        cleaned = cleaned.rstrip(" ,.-")
        for prefix in [
            f"AS{asn}",
            f"(AS{asn})",
            f"AS {asn}",
            f"(AS {asn})",
            f"ASN{asn}",
            f"(ASN{asn})",
            f"ASN {asn}",
            f"(ASN {asn})",
            f"{asn}",
            f"({asn})",
        ]:
            if cleaned.lower().endswith(
                tuple(f"{sep}{prefix.lower()}" for sep in (" ", ",", "-"))
            ):
                cleaned = cleaned[: -len(prefix)]
    if cleaned:
        return cleaned
    return name


def main(options):
    """Create CSV file."""
    asns = {}
    asns.update(from_csv("DB-IP", options.db_ip_url, asn=2, name=3))
    asns.update(from_irr("AFRINIC", f"{options.afrinic_url}/afrinic.db.gz"))
    asns.update(
        from_irr(
            "APNIC",
            f"{options.apnic_url}/apnic.db.aut-num.gz",
            f"{options.apnic_url}/apnic.db.organisation.gz",
        ),
    )
    asns.update(from_irr("ARIN", f"{options.arin_url}/arin.db.gz"))
    asns.update(
        {
            asn: (name.removeprefix("LACNIC generated autnum for "), source)
            for asn, (name, source) in from_irr(
                "LACNIC", f"{options.lacnic_url}/lacnic.db.gz"
            ).items()
        },
    )
    asns.update(
        from_irr(
            "RIPE",
            f"{options.ripe_url}/ripe.db.aut-num.gz",
            f"{options.ripe_url}/ripe.db.organisation.gz",
        ),
    )
    asns.update(from_peeringdb(options.peeringdb_url))

    data = [
        (asn, clean(name, asn, source), source) for asn, (name, source) in asns.items()
    ]
    data.sort()
    w = csv.writer(
        sys.stdout, dialect=options.csv_dialect, quoting=csv.QUOTE_NONNUMERIC
    )
    w.writerow(("asn", "name", "source"))
    for d in data:
        w.writerow(d)


if __name__ == "__main__":
    options = parse_args()
    setup_logging(options)

    try:
        main(options)
    except Exception as e:
        logger.exception("%s", e)
        sys.exit(1)
    sys.exit(0)
